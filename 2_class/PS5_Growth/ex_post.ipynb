{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Økonometri A\n",
    "\n",
    "# Problem set 5\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vækstregressioner: Absolut og betinget konvergens\n",
    "\n",
    "I denne ugeseddel skal I udvide regressionsmodellen fra ugeseddel 3, hvor I så på hypotesen om absolut og betinget konvergens, ved at inkludere information om hvert lands humankapital. I Makroøkonomi A vil I se, at en model uden humankapital vil underestimere betydningen af opsparing og befolkningsvækst på BNP pr. arbejder og samtidig overestimere hastigheden af, hvor hurtigt et land konvergerer mod en vækstbane.\n",
    "\n",
    "I skal tilføje en variabel i regressionsmodellen, som viser investeringsraten i humankapital korrigeret for befolkningsudviklingen, afskrivningsrate og teknologisk fremgang. I skal ligesom i ugeseddel 3 anvende en afskrivningsrate og vækst i teknologi på 0,075. Som en udvidelse til ugeseddel 3 skal I formelt teste forskellige hypoteser om absolut og betinget konvergens. I skal forklare, hvornår I skal bruge et _F_-test og et _t_-test og under hvilke antagelser, de giver valide resultater.\n",
    "\n",
    "Regressionsmodellen med humankapital kan omskrives til:\n",
    "\n",
    "$$\n",
    "gy_i = \\beta_0 + \\beta_1 \\log (y60_i) + \\beta_2 strucK_i + \\beta_3 strucH_i + \\epsilon_i \\tag{1}\n",
    "$$\n",
    "\n",
    "hvor de strukturelle karakteristika er \n",
    "- $ strucK_i = \\ln(sk_i) - \\ln(n_i + 0,075) $ \n",
    "- og $  strucH_i = \\ln(sh_i) - \\ln(n_i + 0,075) $\n",
    "\n",
    "I skal anvende det samme datasæt, som I brugte til ugeseddel 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Gruppespørgsmål\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opgave 1 \n",
    "I kan pålægge en model parameterrestriktioner for at omskrive den til en mere simpel model og indføre disse som en nulhypotese. Den udvidede Solow-model (1) indeholder også den simple regressionsmodel fra spørgsmål 4 i ugeseddel 3, hvor I så på hypotesen om absolut konvergens. Hvad er parameterrestriktionerne og derved nulhypotesen i den udvidede model (1), hvis I gerne vil teste hypotesen om absolut konvergens? Hvad er alternativ hypotesen?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dit svar:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Parameterrestiktionerne i den udvidede Solow model (1) for at teste hypotesen om absolut konvergens er, at de strukturelle karakteristika ikke har en betydning i modellen. Nulhypotesen er $H_0: \\beta_2 = \\beta_3 = 0$. Alternativ hypotesen er $H_A: \\beta_2 \\neq 0 \\vee \\beta_3 \\neq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opgave 2 \n",
    "Giv et forslag til et relevant test, som I kan bruge til at teste nulhypotesen i gruppespørgsmål 1. Hvad er antallet af parameterrestriktioner, som I gerne vil teste?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dit svar:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For at teste nulhypotesen i gruppespørgsmål 1 skal vi bruge et _F_-test, da der er to parameterrestriktioner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opgave 3\n",
    "\n",
    "Hvilke antagelser skal være opfyldt for, at det foreslåede test i gruppespørgsmål 2 er validt?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dit svar:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Antagelserne MLR.1 til MLR.6 skal være opfyldt for, at _F_-testet er validt (slå dem op, hvis du har behov for det). Antagelsen om normalfordelte fejlled (MLR.6) er en restriktiv antagelse – den kan erstattes af en antagelse om, at fejlledet går mod at være normalfordelt, når antallet af observationer går imod uendelig.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Python øvelser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Opgave 1\n",
    "Indlæs data i Python. Fjern de lande, som har datakvalitet D, og lande, som mangler observationer for investeringsraten i humankapital, **sh**. Herefter bør I have 77 lande tilbage.\n",
    "\n",
    "_Hint:_ Hvis du vil tjekke om en variabel indeholder manglende observationer kan du bruge en af de to komplementære kommandoer:\n",
    "```py\n",
    "df['sh'].notnull()\n",
    "df['sh'].isnull()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Din kode:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>iso3</th>\n",
       "      <th>y03</th>\n",
       "      <th>y60</th>\n",
       "      <th>gy</th>\n",
       "      <th>sk</th>\n",
       "      <th>sh</th>\n",
       "      <th>u</th>\n",
       "      <th>isi</th>\n",
       "      <th>n</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>0.189912</td>\n",
       "      <td>0.115346</td>\n",
       "      <td>12.049</td>\n",
       "      <td>0.97333</td>\n",
       "      <td>0.016080</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>IRL</td>\n",
       "      <td>0.971402</td>\n",
       "      <td>0.423321</td>\n",
       "      <td>0.037025</td>\n",
       "      <td>0.209641</td>\n",
       "      <td>0.125219</td>\n",
       "      <td>9.351</td>\n",
       "      <td>0.76672</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norway</td>\n",
       "      <td>NOR</td>\n",
       "      <td>0.968075</td>\n",
       "      <td>0.761374</td>\n",
       "      <td>0.023295</td>\n",
       "      <td>0.283681</td>\n",
       "      <td>0.103698</td>\n",
       "      <td>11.848</td>\n",
       "      <td>0.87272</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>BEL</td>\n",
       "      <td>0.906815</td>\n",
       "      <td>0.663650</td>\n",
       "      <td>0.024969</td>\n",
       "      <td>0.224658</td>\n",
       "      <td>0.101057</td>\n",
       "      <td>9.338</td>\n",
       "      <td>0.86572</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>0.880988</td>\n",
       "      <td>0.554981</td>\n",
       "      <td>0.028456</td>\n",
       "      <td>0.240480</td>\n",
       "      <td>0.095199</td>\n",
       "      <td>8.354</td>\n",
       "      <td>0.86356</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Tanzania</td>\n",
       "      <td>TZA</td>\n",
       "      <td>0.025963</td>\n",
       "      <td>0.028716</td>\n",
       "      <td>0.015365</td>\n",
       "      <td>0.048912</td>\n",
       "      <td>0.006915</td>\n",
       "      <td>2.705</td>\n",
       "      <td>0.27567</td>\n",
       "      <td>0.028053</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Malawi</td>\n",
       "      <td>MWI</td>\n",
       "      <td>0.023686</td>\n",
       "      <td>0.026768</td>\n",
       "      <td>0.014864</td>\n",
       "      <td>0.096660</td>\n",
       "      <td>0.011803</td>\n",
       "      <td>3.204</td>\n",
       "      <td>0.25133</td>\n",
       "      <td>0.025739</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Madagascar</td>\n",
       "      <td>MDG</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>0.078392</td>\n",
       "      <td>-0.010462</td>\n",
       "      <td>0.039704</td>\n",
       "      <td>0.030596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.23800</td>\n",
       "      <td>0.025138</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>ETH</td>\n",
       "      <td>0.023061</td>\n",
       "      <td>0.026356</td>\n",
       "      <td>0.014604</td>\n",
       "      <td>0.035875</td>\n",
       "      <td>0.014008</td>\n",
       "      <td>9.988</td>\n",
       "      <td>0.19933</td>\n",
       "      <td>0.021697</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Burundi</td>\n",
       "      <td>BDI</td>\n",
       "      <td>0.021141</td>\n",
       "      <td>0.037568</td>\n",
       "      <td>0.004339</td>\n",
       "      <td>0.038041</td>\n",
       "      <td>0.005237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.26390</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       country iso3       y03       y60        gy        sk        sh       u  \\\n",
       "1          USA  USA  1.000000  1.000000  0.017709  0.189912  0.115346  12.049   \n",
       "2      Ireland  IRL  0.971402  0.423321  0.037025  0.209641  0.125219   9.351   \n",
       "3       Norway  NOR  0.968075  0.761374  0.023295  0.283681  0.103698  11.848   \n",
       "4      Belgium  BEL  0.906815  0.663650  0.024969  0.224658  0.101057   9.338   \n",
       "5      Austria  AUT  0.880988  0.554981  0.028456  0.240480  0.095199   8.354   \n",
       "..         ...  ...       ...       ...       ...       ...       ...     ...   \n",
       "91    Tanzania  TZA  0.025963  0.028716  0.015365  0.048912  0.006915   2.705   \n",
       "92      Malawi  MWI  0.023686  0.026768  0.014864  0.096660  0.011803   3.204   \n",
       "93  Madagascar  MDG  0.023345  0.078392 -0.010462  0.039704  0.030596     NaN   \n",
       "94    Ethiopia  ETH  0.023061  0.026356  0.014604  0.035875  0.014008   9.988   \n",
       "95     Burundi  BDI  0.021141  0.037568  0.004339  0.038041  0.005237     NaN   \n",
       "\n",
       "        isi         n grade  \n",
       "1   0.97333  0.016080     A  \n",
       "2   0.76672  0.010019     A  \n",
       "3   0.87272  0.012205     A  \n",
       "4   0.86572  0.004503     A  \n",
       "5   0.86356  0.002440     A  \n",
       "..      ...       ...   ...  \n",
       "91  0.27567  0.028053     C  \n",
       "92  0.25133  0.025739     C  \n",
       "93  0.23800  0.025138     C  \n",
       "94  0.19933  0.021697     C  \n",
       "95  0.26390  0.016599     C  \n",
       "\n",
       "[77 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_stata('PS3.dta')\n",
    "df = df[df.grade != 'D']\n",
    "df = df[df.sh.notnull()]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### --- INTERMISSION --- \n",
    "Inden vi går videre med de næste opgaver, skal I lære en smart genvej i `statsmodels`, som gør det lidt simplere at køre regressioner. \n",
    "\n",
    "Indtil videre har vi manuelt udformet vores $X$-matrix, tilføjet en konstant og udformet vores $y$-vektor. Alt det kan vi faktisk springe over og i stedet bare specificere vores ønskede model med en tekststreng. Til det formål skal vi lige importere et nyt model fra statsmodels:\n",
    "\n",
    "```py\n",
    "import statsmodels.formula.api as smf\n",
    "```\n",
    "\n",
    "Prøv nu fx at regressere BNP vækst (`gy`) på befolkningstilvækst (`n`) og investeringsraten i kapital per indbygger (`sk`). Brug kommandoen\n",
    "```py\n",
    "results = smf.ols('gy ~ n + sk', data=df).fit()\n",
    "print(results.summary())\n",
    "```\n",
    "\n",
    "Som du kan se af outputtet sørger statsmodels selv for at tilføje en konstant. Hvis du vil tilføje flere forklarende variable til regressionen, skal du bare tilføje flere led til tekststrengen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Din kode:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     gy   R-squared:                       0.277\n",
      "Model:                            OLS   Adj. R-squared:                  0.258\n",
      "Method:                 Least Squares   F-statistic:                     14.18\n",
      "Date:                Thu, 12 Sep 2024   Prob (F-statistic):           6.11e-06\n",
      "Time:                        20:19:09   Log-Likelihood:                 242.27\n",
      "No. Observations:                  77   AIC:                            -478.5\n",
      "Df Residuals:                      74   BIC:                            -471.5\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.0118      0.005      2.466      0.016       0.002       0.021\n",
      "n             -0.2699      0.141     -1.920      0.059      -0.550       0.010\n",
      "sk             0.0634      0.016      4.026      0.000       0.032       0.095\n",
      "==============================================================================\n",
      "Omnibus:                        0.568   Durbin-Watson:                   2.051\n",
      "Prob(Omnibus):                  0.753   Jarque-Bera (JB):                0.708\n",
      "Skew:                           0.164   Prob(JB):                        0.702\n",
      "Kurtosis:                       2.664   Cond. No.                         118.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "results = smf.ols('gy ~ n + sk', data=df).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opgave 2\n",
    "Estimer den udvidede model (1) med `statsmodels`. Hvad er fortolkningen af $ \\widehat{\\beta}_1 $? Sammenlign estimatet af $ \\beta_1 $ fra spørgsmål 7 i ugeseddel 3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Din kode:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     gy   R-squared:                       0.418\n",
      "Model:                            OLS   Adj. R-squared:                  0.394\n",
      "Method:                 Least Squares   F-statistic:                     17.50\n",
      "Date:                Thu, 12 Sep 2024   Prob (F-statistic):           1.17e-08\n",
      "Time:                        20:19:09   Log-Likelihood:                 250.63\n",
      "No. Observations:                  77   AIC:                            -493.3\n",
      "Df Residuals:                      73   BIC:                            -483.9\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.0029      0.003      0.998      0.322      -0.003       0.009\n",
      "lny60         -0.0075      0.002     -4.441      0.000      -0.011      -0.004\n",
      "strucK         0.0124      0.003      4.611      0.000       0.007       0.018\n",
      "strucH         0.0054      0.003      1.980      0.052   -3.62e-05       0.011\n",
      "==============================================================================\n",
      "Omnibus:                        6.516   Durbin-Watson:                   1.963\n",
      "Prob(Omnibus):                  0.038   Jarque-Bera (JB):                5.835\n",
      "Skew:                          -0.641   Prob(JB):                       0.0541\n",
      "Kurtosis:                       3.419   Cond. No.                         7.81\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "df['lny60'] = np.log(df.y60)\n",
    "df['strucK'] = np.log(df.sk) - np.log(df.n + 0.075)\n",
    "df['strucH'] = np.log(df.sh) - np.log(df.n + 0.075)\n",
    "\n",
    "results = smf.ols('gy ~ lny60 + strucK + strucH', data=df).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dit svar:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Estimation af den udvidede Solow model (1). Fortolkningen af $\\widehat{\\beta}_1$ er, at hvis BNP pr. arbejder er 1 pct. større i 1960, vil den årlige vækstrate i BNP pr. arbejder fra 1960 til 2003 være -0,0075 pct. point lavere. \n",
    ">\n",
    "> Estimatet af $\\beta_1$ i den udvidede Solow model er numerisk større end i modellen fra ugeseddel 3. Det kan forklares ud fra den indledende tekst i ugesedlen, at en model uden human kapital vil overestimere konvergenshastigheden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opgave 3\n",
    "Hvad er nul- og alternativ hypotesen for modellens samlede signifikans? Hvilket test skal I bruge for at teste nulhypotesen? Hvad er teststørrelsen og den kritiske værdi, og kan nulhypotesen afvises? Vær præcise, når I formulerer nul- og alternativ hypotesen i ord.\n",
    "\n",
    "_Hint:_ for at finde den kritiske værdi til et _F_-test kan du bruge Python-pakken scipy:\n",
    "```py\n",
    "import scipy\n",
    "q = ... # det ønskede signifikansniveau\n",
    "dfn = ... # antal frihedsgrader i tælleren\n",
    "dfd = ... # antal frihedsgrader i nævneren\n",
    "scipy.stats.f.ppf(1-q, dfn, dfd)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7300187139961727"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "q = 0.05\n",
    "dfn = 3\n",
    "dfd = 73\n",
    "scipy.stats.f.ppf(1-q, dfn, dfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dit svar:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nulhypotesen for modellens samlede signifikans er $H_0: \\beta_1 = \\beta_2 = \\beta_3 = 0$. Alternativ hypotesen er $H_A:$ mindst én $\\beta_j \\neq 0, j=1,2,3$. \n",
    "> \n",
    "> Hvis vi skal formulere nulhypotesen i ord, er den, at BNP pr. arbejder i 1960 og strukturelle karakteristika ikke samlet set kan forklare væksten i BNP pr. arbejder fra 1960 til 2003, hvormed hypotesen om absolut og betinget konvergens ikke er understøttet empirisk.\n",
    ">\n",
    "> Vi skal anvende et _F_-test for at teste nulhypotesen. Aflæs _F_-teststørrelsen i regressionsoutputtet i Python til $F(3,73)=17,50$. Den kritiske værdi på et 5 pct. signifikansniveau er 2,73. Når den kritiske værdi er mindre end teststørrelsen, kan nulhypotesen afvises, så BNP pr. arbejder i 1960 og strukturelle karakteristika samlet set kan forklare væksten i BNP pr. arbejder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Opgave 4\n",
    "Hvad er nul- og alternativ hypoteserne for hver af de individuelle forklarende variable? Hvilket test skal I bruge for at teste nulhypoteserne? Hvad er teststørrelserne og den kritiske værdi, og kan nulhypoterne afvises? Vær præcise, når I formulerer nul- og alternativ hypoteserne i ord.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dit svar:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9912543951146038"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.t.ppf(1-0.025, df=77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nulhypoteserne for hver af de individuelle forklarende variable er $H_0: \\beta_j = 0, j=1,2,3$. Alternativ hypotesen er $H_A: \\beta_j \\neq 0, j=1,2,3$. Hvis vi skal formulere en af nulhypoteserne i ord, f.eks. for $\\beta_2$, er det, at fysisk kapital ikke kan forklare væksten i BNP pr. arbejder fra 1960 til 2003. \n",
    "> \n",
    "> Vi skal anvende _t_-test til at teste de tre nulhypoteser for hver af de forklarende variable. Aflæs _t_-teststørrelserne i regressionsoutputtet i Python til hhv. -4,44, 4,61 og 1,98. Den kritiske værdi på et 5 pct. signifikansniveau kan findes enten ud fra en standard normalfordeling til $\\pm$ 1,96 eller ud fra en _t_-fordeling. Her kan vi anvende scipy med kommandoen `scipy.stats.t.ppf(q=1-0.025, df=77)` og finde den kritiske værdi til 1,99. Den kritiske værdi er ikke helt ens med de to metoder, da antallet af observationer i lavt. Estimaterne af $\\beta_1$ og $\\beta_2$ er signifikante, så både BNP pr. arbejder i 1960 og fysisk kapital kan forklare væksten i BNP pr. arbejder. Estimatet af $\\beta_3$ er borderline, da _t_-teststørrelsen er tæt på den kritiske værdi.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Opgave 5\n",
    "Hvad er en passende alternativ hypotese, når I tester $ \\beta_1 = 0 $ i model (1)? Udfør testet. \n",
    "\n",
    "[Hint: Hvilken betydning har hypotesen om betinget konvergens for $ \\beta_1 $? Tag udgangspunkt i gruppespørgsmål i ugeseddel 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6648845371855607"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.t.ppf(1-0.05, df=77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> En passende alternativ hypotese, når vi skal teste hypotesen om betinget konvergens, er $H_A: \\beta_1 < 0$, da initialt fattige lande skal have en højere vækst i BNP pr. arbejder, end lande, som er rige i 1960. _t_-teststørrelsen er den samme som i spørgsmål 4. Den kritiske værdi skal afspejle et en-sidet test, som kan findes enten ud fra en standard normalfordeling til -1,64 eller ud fra en _t_-fordeling. Her kan vi anvende Python kommandoen `scipy.stats.t.ppf(q=0.95, df=77)` og finde den kritiske værdi til -1,66. Nulhypotesen $\\beta_1=0$ kan afvises, når teststørrelsen er numerisk mindre end den kritiske værdi, så hypotesen om betinget konvergens bliver understøttet empirisk i dette tilfælde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Opgave 6\n",
    "I skal nu undersøge, om de strukturelle karakteristika samlet set kan udelades fra regressionsmodellen. Opskriv den relevante nulhypotese til F-testet ved at tage udgangspunkt i gruppespørgsmålene.\n",
    "\n",
    "1. Udregn _F_-testet i hånden. I skal tage udgangspunkt i ligning [4.37] i Wooldridge (7. udgave). I skal bruge resultaterne fra spørgsmål 2 samt estimere en restrikteret model, hvor nulhypotesen fra gruppespørgsmålene er pålagt.\n",
    "\n",
    "2. Lad Python udregne _F_-testet. Hvis dit OLS resultat-objekt fra statsmodels hedder `results` kan du bruge følgende kommando:\n",
    "\n",
    "    ```py\n",
    "    hypotheses = '(strucK = strucH = 0)'\n",
    "    f_test = results.f_test(hypotheses)\n",
    "    print(f_test)\n",
    "    ```\n",
    "3. Tjek at resultaterne  er ens.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Din kode:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-test\n",
      "26.233555200023\n",
      "Critical value\n",
      "3.1221029319882803\n"
     ]
    }
   ],
   "source": [
    "# Manual calculation of F_test\n",
    "## 1. Get the SSR of the restricted model\n",
    "results_r = smf.ols('gy ~ lny60', data=df).fit()\n",
    "SSR_r = results_r.ssr\n",
    "\n",
    "## 2. Get the SSR of the unrestricted model\n",
    "results_ur = smf.ols('gy ~ lny60 + strucK + strucH', data=df).fit()\n",
    "SSR_ur = results.ssr\n",
    "\n",
    "## 3. Calculate the F-test\n",
    "F_test_manual = ((SSR_r-SSR_ur)/2) / (SSR_ur/(77-3-1))\n",
    "print('F-test')\n",
    "print(F_test_manual)\n",
    "\n",
    "## 4. Print critical value\n",
    "print('Critical value')\n",
    "print(scipy.stats.f.ppf(1-0.05, 2, 73))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<F test: F=26.233555200022995, p=2.5998194642764728e-09, df_denom=73, df_num=2>\n"
     ]
    }
   ],
   "source": [
    "# Statsmodels F-test\n",
    "hypotheses = '(strucK = strucH = 0)'\n",
    "f_test = results.f_test(hypotheses)\n",
    "print(f_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dit svar:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\n",
    "> 1.  Ligning [4.37]: \n",
    "> \\begin{align*}\n",
    ">     F = \\frac{SSR_r-SSR_{ur}/q}{SSR_{ur}/(n-k-1)}\n",
    "> \\end{align*}\n",
    "> Vi skal finde residual variationen fra hhv. den restrikterede og urestrikterede model. $q$ er antallet af parameterrestriktioner, $n$ er antallet af observationer og $k$ er antallet af parametre i modellen. _F_-teststørrelsen bliver 26,23. <br><br>\n",
    "> Vi finder den kritiske værdi med kommandoen \n",
    "> `scipy.stats.f.ppf(0.95, 2, 73)`\n",
    ">  til 3,12. Nulhypotesen om, at de strukturelle karakteristika ikke har en betydning for modellen, og at modellen kan reduceres til den simple model med absolut konvergens, kan afvises. Dette giver empirisk evidens for betinget konvergens. \n",
    "> \n",
    "> 2. _F_-teststørrelsen er den samme, som vi fandt med formlen: $F(2,73) =$ 26,23. Ligeledes med den kritiske værdi.\n",
    "> \n",
    "> 3. Resultaterne er ens med de to metoder.\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Opgave 7\n",
    "I dette spørgsmål skal I implementere jeres egen version af OLS-estimatoren i MLR-tilfældet – ligesom i Problem Set 3. Denne gang skal jeres implementerede funktion dog både returnere OLS-parameterestimaterne og deres standardfejl.\n",
    " \n",
    "Ligning (2) og (3) nedenfor viser formlen for OLS-estimatoren med homoskedastiske standardfejl.\n",
    "\n",
    "$$\n",
    "\\widehat{\\beta} = (X'X)^{-1}X'y \\tag{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{var}(\\widehat{\\beta} | X) = \\sigma^2 (X'X)^{-1}, \\quad \\sigma^2 = \\frac{1}{N-K} \\widehat{U}' \\widehat{U} \\tag{3}\n",
    "$$\n",
    "\n",
    "hvor \n",
    "- $ N $ er antallet af observationer, \n",
    "- $ K $ er antallet af parametre inkl. et konstantled \n",
    "- $ \\widehat{U} \\equiv y - X\\widehat{\\beta} $ er residualerne.\n",
    "- $ \\sigma^2 $ er residualvariansen\n",
    "- Standardfejlene er kvadratroden af diagonalelementerne i kovarians-matricen $\\text{var}(\\widehat{\\beta} | X)$\n",
    "\n",
    "Brug din funktion til at estimere model (1) og bekræft, at du får de samme parameterestimator og standardfejl som statsmodels giver.\n",
    "\n",
    "_Tip:_ Du kan tilgå diagonalelementerne af en matrix $A$ i numpy ved hjælp af `np.diagonal(A)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols(X, y):\n",
    "    beta_hat = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    U_hat = y - X @ beta_hat\n",
    "    N = X.shape[0]\n",
    "    K = X.shape[1]\n",
    "    SSR = U_hat.T @ U_hat\n",
    "    sigma2 = SSR * 1/(N - K)\n",
    "    var_beta_hat = sigma2 * np.linalg.inv(X.T @ X)\n",
    "    se_ols = np.sqrt(np.diag(var_beta_hat))\n",
    "    \n",
    "    return beta_hat, se_ols    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kør nedenstående celle for at estimere model (1) ved hjælp af din egen funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vars\n",
      "const, lny60, strucK, strucH\n",
      "beta_hat\n",
      "[ 0.0029 -0.0075  0.0124  0.0054]\n",
      "se_beta_hat\n",
      "[0.0029 0.0017 0.0027 0.0027]\n"
     ]
    }
   ],
   "source": [
    "X = df[['lny60', 'strucK', 'strucH']].values\n",
    "X = sm.add_constant(X)\n",
    "y = df['gy']\n",
    "\n",
    "beta_hat, se_beta_hat = ols(X, y)\n",
    "\n",
    "print('vars')\n",
    "print('const, lny60, strucK, strucH')\n",
    "print('beta_hat')\n",
    "print(beta_hat.round(4))\n",
    "print('se_beta_hat')\n",
    "print(se_beta_hat.round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
