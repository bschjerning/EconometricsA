{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#import statsmodels formula\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstatsmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformula\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msmf\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "#import statsmodels formula\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Økonometri A  \n",
    "\n",
    "## Problem Set 6  \n",
    "\n",
    "### Hedonic price regressions  \n",
    "\n",
    "In problem set 6, we estimate a regression model relating house prices to house characteristics. This model is an example of the so-called hedonic price regression which is widely used in economics.\n",
    "\n",
    "A hedonic regression for house prices usually includes house characteristics and community attributes as explanatory variables. In this case, the model's coefficients may be interpreted as the implicit price of each characteristic. Hedonic price models can be useful for estimating the price of characteristics for which there are no markets. For example, we do not observe a price for clean air, but we may be able to estimate the (implicit) price effect of clean air on house prices.\n",
    "\n",
    "The data used in problem set 6 contains a random sample of apartment sales in Copenhagen in 2005. We will focus on apartments sold in the four neighborhoods of Copenhagen K, N, V, and Ø. For each apartment, we observe the sales price and a range of apartment characteristics which are all specific to the year of 2005. We consider these data as a cross-section, exploiting variation in prices and characteristics across apartments to estimate the parameters of the hedonic price regression.\n",
    "\n",
    "The STATA file `PS6.dta` includes the following variables for a total of 988 apartment sales in 2005:\n",
    "\n",
    "- Sales price in 2005-DKK (**price**)\n",
    "- Apartment size in square meters (**m2**)\n",
    "- Number of rooms (**rooms**)\n",
    "- Number of toilets (**toilets**)\n",
    "- Floor location of apartment (**floor**)\n",
    "- Apartment location in Copenhagen (**location**)\n",
    "- Number of apartment units in the building (**building_units**)\n",
    "- Building age (**age**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Group work  \n",
    "\n",
    "Discuss the following questions in groups:\n",
    "\n",
    "#### Question 1.\n",
    "\n",
    "Consider the simple hedonic model:\n",
    "\n",
    "$$\n",
    "\\log(price_i) = \\beta_0 + \\beta_1 m2_i + \\beta_2 rooms_i + \\beta_3 toilets_i + u_i \\tag{1}\n",
    "$$\n",
    "\n",
    "\n",
    " Discuss if it is reasonable to assume that assumptions MLR.1–MLR.5 are satisfied for model (1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - MLR.1: Modellen antager at der er et linært forhold mellem boligpriser og de forklarende variable. Det kan godt være problematisk, hvilket ses i den sidste Python-øvelse, hvor det kvadratiske led for _m2_ indgår stærkt signifikant.\n",
    ">\n",
    "> - MLR.2: Antagelsen om en tilfældig stikprøve er opfyldt, jf. databeskrivelsen.\n",
    "> - MLR.3: Antagelsen om ingen perfekt multikollinearitet er opfyldt, omend variablen toilets har begrænset variation i data.\n",
    "> - MLR.4: Der er mange udeladte variable hvorfor det kan være svært at retfærdiggøre antagelsen $E(u|X) = 0$. Omvendt kan stille spørgsmål ved om de udeladte variable har en stor effekt på prisen. Her kan vi huske bias-formlen for OLS-estimatoren, som viser at biasen afhænger af korrelationen mellem $u$ og $x$, samt de udeladte variables partielle effekt på boligpriser\n",
    "> \n",
    "> - MLR.5: Antagelsen om homoskedasticitet kan også diskuteres. Det virker ikke urimeligt at fx store lejligheder har en større varians på deres prischok (fejlleddet) sammenlignet med mindre lejligheder. Dette vender vi tilbage til i ugeseddel 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 2.\n",
    " The hedonic model can be extended with dummy variables to investigate if there are level differences between apartments in different neighbourhoods of Copenhagen. Note that the variable **location** takes on four categories:\n",
    " _KBH K_, _KBH N, KBH O_ and _KBH V_\n",
    "\n",
    " The extended model with dummy variables could look like this:\n",
    " \n",
    " \\begin{align}\n",
    " \t\t\\log(price_i)=\\, &\\beta_0 +\\delta_1 KbhN_i + \\delta_2 KbhO_i + \\delta_3 KbhV_i \\\\\n",
    " \t\t\t      &+\\beta_1 m2_i + \\beta_2 rooms_i + \\beta_3 toilets_i \n",
    " \t\t\t      + \\epsilon_i \n",
    " \t\\end{align}\\tag{2}\n",
    "\n",
    "1. Explain what a dummy variable is.\n",
    "\n",
    "2. Why don't we include dummies for _Kbh K_ model (2)? \n",
    "\n",
    "3. In terms of the model parameters, what is the intercept for apartments located in Kbh V?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. En dummy variabel er en variabel, som antager værdien 0 eller 1. Vi bruger dummy variable til at modellere kvalitative forhold. I model (2) har vi tre dummy variable, som henholdsvis antager værdien 1 hvis  lejligheden befinder sig i Kbh K, på Nørrebro eller på Vesterbro. I alle andre tilfælde er værdien nul.\n",
    "> \n",
    "> 2. Når vi har med kategoriske variable at gøre, udelader vi altid én kategori for at undgå at gå i \"dummy-fælden\", som ellers vil få modellen til at overtræde MLR.3. I vores modelspecifikation er Kbh K udeladt og fungerer derfor som referencekategori.\n",
    "> \n",
    "> 3. Interceptet for lejligheder på Vesterbro er $\\beta_0 + \\delta_3$. Hvorfor? $\\beta_0$ er interceptet for København K-lejligheder (referencekategorien), mens $\\delta_3$ er forskellen på referencekategorien og Vesterbro-lejligheder. Derfor er $\\beta_0 + \\delta_3$ interceptet for lejligheder på Vesterbro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3. \n",
    "The hedonic model can further be extended with interaction terms to see if the model parameters differ across locations in Copenhagen.\n",
    "\n",
    "\\begin{align}\n",
    " \t\t\\log(price_i)=\\, &\\beta_0 +\\delta_1 KbhN_i + \\delta_2 KbhO_i + \\delta_3 KbhV_i \\\\\n",
    " \t\t\t      &+\\beta_1 m2_i  +\\delta_4 KbhN_i\\cdot m2_i  + \\delta_5 KbhO_i\\cdot m2_i  + \\delta_6 KbhV_i\\cdot m2_i  \\\\\n",
    "                  &+\\beta_2 rooms_i +\\delta_7 KbhN_i\\cdot rooms_i  + \\delta_8 KbhO_i\\cdot rooms_i + \\delta_9 KbhV_i\\cdot rooms_i \\\\\n",
    " \t\t          &+ \\beta_3 toilets_i +\\delta_{10} KbhN_i\\cdot toilets_i  + \\delta_{11} KbhO_i\\cdot toilets_i + \\delta_{12} KbhV_i\\cdot toilets_i \\\\\n",
    " \t\t\t      & + \\epsilon_i \n",
    " \t\\end{align}\\tag{3}\n",
    "\n",
    "1. Which coefficients in model (3) describe the interaction terms?\n",
    "\n",
    "2. In terms of the model parameters, what is the expected log(price) for a  $ 75 m^2$ apartment in _Kbh V_ with three rooms and one toilet?\n",
    "\n",
    "3. What is the expected log(price) for an identical apartment in _Kbh K_?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">1. Interaktionsledenes koefficienter er $\\delta_4, \\delta_5, ..., \\delta_{11}, \\delta_{12}$\n",
    ">\n",
    ">2. Den forventede log(pris) for Vesterbro-lejligheden er: $(\\beta_0 + \\delta_3) + 75 \\cdot (\\beta_1 + \\delta_6) + 3 \\cdot (\\beta_2  + \\delta_9)  + 1 \\cdot (\\beta_3 + \\delta_{12}) $\n",
    ">\n",
    ">3. Den forventede log(pris) for København K-lejligheden er: $\\beta_0 + 75 \\beta_1 +  3\\beta_2 + 1 \\beta_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 4.\n",
    " How can you test for level differences in apartment prices across Copenhagen? How can you test if the (implicit) price of an additional square meter is different across locations in Copenhagen? Formulate the null and alternative hypotheses (be precise!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Med udgangspunkt i model (2) kan hypotesen om ingen niveauforskelle i\n",
    "boligpriser på tværs af beliggenhed opskrives som:\n",
    "> \\begin{align*}\n",
    "\t\tH_0 : \\delta_1=\\delta_2=\\delta_3=0\n",
    "\t\\end{align*}\n",
    "> Tilsvarende kan hypotesen om en identisk implicit kvadrameterpris på tværs af beliggenhed i model (3)  opstilles som:\n",
    ">\n",
    ">\t\\begin{align*}\n",
    "\t\tH_0 : \\delta_4=\\delta_5=\\delta_6=0\n",
    "\t\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Python exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 0: Warm-up\n",
    "\n",
    "In this problem set, it will be useful for you to know a little about two very useful Python features, namely **f-strings** and **list comprehension**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### f-strings \n",
    "f-strings lets you plug Python variables directly into your strings. Consider the example below:\n",
    "```py\n",
    "name = 'Daniel'\n",
    "age = 30 + 1\n",
    "greeting = f'My name is {name}, great to meet you! I am {age} years old'\n",
    "\n",
    "print(greeting)\n",
    "```\n",
    "\n",
    "```txt\n",
    ">> My name is Daniel, great to meet you! I am 31 years old\n",
    "```\n",
    "\n",
    "So by simply adding an 'f' in front of your strings, you get the superpower of being able to include the contents of variables directly in your strings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### List comprehension\n",
    "List comprehension is another useful tool that allows you quickly to generate transformations of existing lists without needing a for loop:\n",
    "```py\n",
    "numbers = [1, 2, 3, 4]\n",
    "numbers2 = [2 * num for num in numbers] # <- list comprehension\n",
    "\n",
    "print(numbers)\n",
    "```\n",
    "\n",
    "```txt\n",
    ">> [2, 4, 6, 8]\n",
    "```\n",
    "List comprehension can also be used to work with strings. And you can loop over multiple lists in the same list comprehension statement. Consider this example:\n",
    "\n",
    "```py\n",
    "letters = ['x', 'y', 'z']\n",
    "numbers = [1, 2, 3, 4]\n",
    "\n",
    "variables = [f'{let}_{num}' for let in letters for num in numbers]\n",
    "\n",
    "print(variables)\n",
    "```\n",
    "\n",
    "```txt\n",
    ">> ['x_1', 'x_2', 'x_3', 'x_4', 'y_1', 'y_2', 'y_3', 'y_4', 'z_1', 'z_2', 'z_3', 'z_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Use your knowledge of list comprehension and f-strings to generate this output from the two lists in the code cell below:\n",
    "\n",
    "```py\n",
    "['C(location)[T.KBH N]:m2',\n",
    " 'C(location)[T.KBH N]:rooms',\n",
    " 'C(location)[T.KBH N]:toilets',\n",
    " 'C(location)[T.KBH O]:m2',\n",
    " 'C(location)[T.KBH O]:rooms',\n",
    " 'C(location)[T.KBH O]:toilets',\n",
    " 'C(location)[T.KBH V]:m2',\n",
    " 'C(location)[T.KBH V]:rooms',\n",
    " 'C(location)[T.KBH V]:toilets']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C(location)[T.KBH N]:m2',\n",
       " 'C(location)[T.KBH N]:rooms',\n",
       " 'C(location)[T.KBH N]:toilets',\n",
       " 'C(location)[T.KBH O]:m2',\n",
       " 'C(location)[T.KBH O]:rooms',\n",
       " 'C(location)[T.KBH O]:toilets',\n",
       " 'C(location)[T.KBH V]:m2',\n",
       " 'C(location)[T.KBH V]:rooms',\n",
       " 'C(location)[T.KBH V]:toilets']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locs = ['KBH N', 'KBH O', 'KBH V']\n",
    "vars = ['m2', 'rooms', 'toilets']\n",
    "loc_vars = [f'C(location)[T.{loc}]:{var}' for loc in locs for var in vars]\n",
    "\n",
    "loc_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.\n",
    "**Load the data set into pandas** and provide a descriptive analysis of sales prices and apartment sizes across different locations in Copenhagen.\n",
    "\n",
    "_Hint 1:_ Remember from Problem Set 1 that we can compute grouped summary statistics by using the `.groupby()` method in a DataFrame.\n",
    "\n",
    "_Hint 2:_ If you don't want all the summary statistics, but just the mean, you can use `.mean()` instead of `.describe()`. This is especially useful when grouping on some category, as the resulting table has a tendency of becoming very big otherwise. Similar useful methods are `.std()`, `.count()`, `.max()`, `.min()` and `.median()`\n",
    "\n",
    "_Hint 3:_ You can use `df['location'].value_counts()` to see the distribution of the observations across the four locations in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 988\n",
      "location\n",
      "KBH O    398\n",
      "KBH N    229\n",
      "KBH K    223\n",
      "KBH V    138\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>m2</th>\n",
       "      <th>rooms</th>\n",
       "      <th>toilets</th>\n",
       "      <th>floor</th>\n",
       "      <th>building_units</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KBH K</th>\n",
       "      <td>2625185.01</td>\n",
       "      <td>90.45</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.44</td>\n",
       "      <td>28.44</td>\n",
       "      <td>1901.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBH N</th>\n",
       "      <td>1672341.64</td>\n",
       "      <td>66.45</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2.28</td>\n",
       "      <td>56.21</td>\n",
       "      <td>1923.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBH O</th>\n",
       "      <td>2404902.39</td>\n",
       "      <td>89.66</td>\n",
       "      <td>2.92</td>\n",
       "      <td>1.09</td>\n",
       "      <td>2.25</td>\n",
       "      <td>47.91</td>\n",
       "      <td>1936.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBH V</th>\n",
       "      <td>2252892.69</td>\n",
       "      <td>85.92</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.36</td>\n",
       "      <td>50.61</td>\n",
       "      <td>1915.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               price     m2  rooms  toilets  floor  building_units      age\n",
       "location                                                                   \n",
       "KBH K     2625185.01  90.45   2.75     1.06   2.44           28.44  1901.07\n",
       "KBH N     1672341.64  66.45   2.29     1.01   2.28           56.21  1923.52\n",
       "KBH O     2404902.39  89.66   2.92     1.09   2.25           47.91  1936.21\n",
       "KBH V     2252892.69  85.92   2.81     1.04   2.36           50.61  1915.03"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_stata('PS6.dta')\n",
    "\n",
    "print(\"Observations:\", df.shape[0])\n",
    "print(df['location'].value_counts())\n",
    "\n",
    "df.groupby('location').mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Data indeholder 988 observationer som fordeler sig som vist øverst.\n",
    ">\n",
    "> Af tabellen nedenunder ses at den gennemsnitlige kvadratmeterpris er højest i Kbh K og lavest i Kbh N. Endvidere ses det lejlighederne er størst i Kbh K —tæt efterfulgt af Kbh Ø"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Task 2.\n",
    "**Assume model (1) satisfies MLR.1–MLR.5.** Estimate model (1) by OLS and comment on the parameter estimates. How much of the variation in $\\log(price)$ can the regression model explain? Is the sign of $\\hat{\\beta}_3$ surprising?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               logprice   R-squared:                       0.562\n",
      "Model:                            OLS   Adj. R-squared:                  0.561\n",
      "Method:                 Least Squares   F-statistic:                     421.1\n",
      "Date:                Wed, 25 Sep 2024   Prob (F-statistic):          6.51e-176\n",
      "Time:                        11:00:44   Log-Likelihood:                -148.92\n",
      "No. Observations:                 988   AIC:                             305.8\n",
      "Df Residuals:                     984   BIC:                             325.4\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     13.9043      0.042    328.925      0.000      13.821      13.987\n",
      "m2             0.0086      0.000     18.879      0.000       0.008       0.010\n",
      "rooms          0.0152      0.014      1.087      0.278      -0.012       0.043\n",
      "toilets       -0.1221      0.043     -2.863      0.004      -0.206      -0.038\n",
      "==============================================================================\n",
      "Omnibus:                       98.182   Durbin-Watson:                   1.938\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              181.594\n",
      "Skew:                          -0.643   Prob(JB):                     3.69e-40\n",
      "Kurtosis:                       4.660   Cond. No.                         587.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "df['logprice'] = np.log(df.price)\n",
    "\n",
    "results1 = smf.ols('logprice ~ m2 + rooms + toilets', data = df).fit()\n",
    "print(results1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tabellen ovenfor rapporterer OLS estimationsresultaterne.\n",
    "> \n",
    ">  Det ses at regressionsmodellen forklarer 56 pct. af variationen i $\\log(boligpriser)$, samt at en større bolig i kvadratmeter eller værelser medfører højere boligpriser (omend den sidste er statistisk insignifikant). En ekstra kvadratmeter forøger således den gennemsnitlig boligpris med 0.8 pct. Antallet af toiletter påvirker derimod den gennemsnitlige boligpris negativt. \n",
    "> \n",
    "> Bemærk at $\\beta_3$ angiver effekten af et ekstra toilet, når antallet af værelser og kvadratmeter fastholdes. Måske er det negative fortegn alligevel ikke så overraskende. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### --- INTERMISSION --- \n",
    "Before we move on with the next exercises, you should learn about a feature in `statsmodels` which makes it a little simpler to run regressions.\n",
    "\n",
    "So far we have manually been choosing our $X$-matrix, added a constant and chosen our $y$-vector. Actually, we can skip all these steps and instead just specify our model using a text string. This is a bit more akin to how one would do the analyis in a software package such as Stata or R. \n",
    "\n",
    "To achieve this, we are going to import a new module from statsmodels:\n",
    "\n",
    "```py\n",
    "import statsmodels.formula.api as smf\n",
    "```\n",
    "\n",
    "Now, try to solve exercise 2 again using this module. Use the command\n",
    "```py\n",
    "df['logprice'] = np.log(df.price)\n",
    "\n",
    "results = smf.ols('logprice ~ m2 + rooms + toilets', data = df).fit()\n",
    "print(results.summary())\n",
    "```\n",
    "\n",
    "As you can see from the output, statsmodels makes sure to automatically add a constnat. If you want to add more explanatory variables to the specification, you just extend the string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Task 3.\n",
    "- Estimate model (2)\n",
    "\n",
    "- Interpret the regression results. What is the estimated price differences across neighbourhoods in percentages?\n",
    "\n",
    "Make sure you understand both hints below before you solve the task.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[ _Hint:_ Assuming your DataFrame is named `df`, this code may be of help when constructing the dummy variables:\n",
    " ```py\n",
    " df['KbhN'] = df.location == \"KBH N\"\n",
    " ```\n",
    " This creates a new column called `KbhN` that is filled with True or False values depending on whether each observation satisfies the condition. When including this variable in a statsmodels regression, it will automatically be interpreted as a dummy (True is 1, False is 0). \n",
    " \n",
    " However, if you want to, you can add this line of code to convert the boolean array to dummies using this code:\n",
    " ```py\n",
    " df['KbhN'] = df['KbhN'].astype('int')\n",
    " ```\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " [_Hint 2:_ Actually you don't have to generate the dummy variables manually.\n",
    " \n",
    " If you are using formulas to specify your model in statsmodels (as we learned in Problem Set 5), you can skip the process described in the former hint entirely and simply add `C(location)` to your formula string to automatically add dummies based on the location categories to your regression model. Statsmodels also automatically leaves out one category to avoid the dummy trap.\n",
    " \n",
    "  You can read more about this feature at https://www.statsmodels.org/stable/example_formulas.html#categorical-variables\n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               logprice   R-squared:                       0.597\n",
      "Model:                            OLS   Adj. R-squared:                  0.595\n",
      "Method:                 Least Squares   F-statistic:                     242.4\n",
      "Date:                Wed, 25 Sep 2024   Prob (F-statistic):          8.58e-190\n",
      "Time:                        11:00:44   Log-Likelihood:                -107.69\n",
      "No. Observations:                 988   AIC:                             229.4\n",
      "Df Residuals:                     981   BIC:                             263.6\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept               14.0421      0.044    320.650      0.000      13.956      14.128\n",
      "C(location)[T.KBH N]    -0.2370      0.026     -9.032      0.000      -0.288      -0.185\n",
      "C(location)[T.KBH O]    -0.0858      0.023     -3.755      0.000      -0.131      -0.041\n",
      "C(location)[T.KBH V]    -0.1307      0.029     -4.441      0.000      -0.189      -0.073\n",
      "m2                       0.0079      0.000     17.553      0.000       0.007       0.009\n",
      "rooms                    0.0230      0.014      1.702      0.089      -0.004       0.050\n",
      "toilets                 -0.1093      0.041     -2.658      0.008      -0.190      -0.029\n",
      "==============================================================================\n",
      "Omnibus:                      119.239   Durbin-Watson:                   2.093\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              259.862\n",
      "Skew:                          -0.702   Prob(JB):                     3.73e-57\n",
      "Kurtosis:                       5.084   Cond. No.                         606.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "results2 = smf.ols('logprice ~ m2 + rooms + toilets + C(location)', data = df).fit()\n",
    "\n",
    "print(results2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tabellen ovenfor viser regressionsresultaterne. Det ses at lejligheder med samme størrelse, og samme antal værelser og toiletter, i gennemsnit har en salgspris der er 23.7 pct. lavere, hvis lejligheden ligger på Nørrebro sammenlignet med Kbh K. På Østerbro er prisen 8.58 pct. lavere relativt til Kbh K (med de samme karakteristika), og på Vesterbro er prisen 13.07 pc. lavere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Use an $F$-test if there are level differences in apartment prices across neighbourhoods of Copenhagen. Be precise in formulating your null and alternative hypothesis.\n",
    "\n",
    "- Why are we using an $F$-test?\n",
    "\n",
    "- What assumptions are necessary for the validity of the test?\n",
    "\n",
    "- Based on your test results, do you prefer model (1) or model (2)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_Hint:_ You can calculate the F-test by hand or use the built-in `.f_test()` function of your statsmodels OLS results object. For example, if you want to test if the coefficiants for $m2$ and $rooms$ are both equal to zero, you would use the code\n",
    "\n",
    "```py\n",
    "ftest = results.f_test(['m2', 'rooms'])\n",
    "\n",
    "print(ftest)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-test:\n",
      "<F test: F=28.465327002259258, p=1.1870777814702191e-17, df_denom=981, df_num=3>\n",
      "\n",
      "Critical value:\n",
      "2.6139762089788743\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "ftest = results2.f_test(['C(location)[T.KBH N]', \n",
    "                        'C(location)[T.KBH O]', \n",
    "                        'C(location)[T.KBH V]'])\n",
    "\n",
    "print('F-test:')\n",
    "print(ftest)\n",
    "\n",
    "# Critical value\n",
    "print('\\nCritical value:')\n",
    "print(stats.f.ppf(0.95, 3, 981))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Hypotesen for ingen niveauforskelle på tværs af beliggenhed er:\n",
    "> \\begin{align*}\n",
    "\t\t&H_0 : \\delta_1=\\delta_2=\\delta_3=0 \\\\\n",
    "\t\t&H_A: \\text{ mindst en } \\delta_j \\neq 0, \\, j=1,2,3\n",
    "\t\\end{align*}\n",
    ">\n",
    "> Vi anvender et F-test da hypotesen indeholder mere end 1 restriktion. Vi har 3 restriktioner: $\\delta_1 = 0, \\delta_2 = 0, \\delta=3 0$, som alle skal være overholdt under vores nulhypotese.\n",
    "> \n",
    "> F-testet beregnes ved brug af den indbyggede .f_test()-funktion i statsmodels. Den beregnede teststørrelse $F = 28.46$ sammenlignes med den relevante kritiske værdi fra en F-fordeling med $((m-1)(k+1),n-m(k+1)) $ frihedsgrader. Her er de relevante frihedsgrader $(3, 981)$ og den kritiske værdi beregnes til 2.61. Ergo forkastes nulhypotesen til fordel for alternativhypotesen. Dette kan også aflæses af den $p$-værdi på 0.0000, som statsmodels rapporterer i F-test resultaterne.\n",
    "> \n",
    "> \n",
    "> Antagelserne MLR.1-MLR.5 og $n \\rightarrow \\infty$ er nødvendige for at testproceduren er valid.\n",
    ">\n",
    "> Ifl. vores test må vi forkaste nulhypotesen og konkludere, at prisniveauet for lejligheder varierer på tværs af kvarterer i København. Vi foretrækker derfor model (2) fremfor model (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Task 5.\n",
    "**Interaction terms for apartment size and location.** \n",
    "1. Estimate the full model (3) with all the interaction terms. Interpret the regression results. Are all the estimated coefficiants individually significant?\n",
    "\n",
    "3. Test whether there are interaction effects across locations in Copenhagen (test if all the interaction terms are jointly 0)\n",
    "\n",
    "4. Test specifically whether the effect of the number of rooms (`rooms`) differs across locations.\n",
    "\n",
    "5. Test specifically whether the price effect of apartment size (`m2`) differs across locations.\n",
    "\n",
    "6. If you want to, try to estimate a new specification based on your test insights to better explain the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Hint:_ If you use formulas to specify your regression model in statsmodels, you can interact two terms in the formula by using the `*` operator instead of `+`. \n",
    "\n",
    "For example, if I wanted to interact `m2` with `rooms`, I could use the code:\n",
    "```py\n",
    "results = smf.ols('logprice ~ toilets + m2 * rooms', data = df).fit()\n",
    "```\n",
    "You can also interact a variable with multiple variables by grouping them in parantheses. For example:\n",
    "```py\n",
    "results = smf.ols('logprice ~ m2*(rooms + toilets)', data = df).fit()\n",
    "```\n",
    "\n",
    "Note that when interacting two variables, statsmodels automatically adds the two variables individually (that is, un-interacted) to the model specification too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Hint:_ Use the output from the warmup exercise (on f-strings and list comprehension) to conduct the first F-test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1 code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================\n",
      "                                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "Intercept                       14.1824      0.089    159.970      0.000      14.008      14.356\n",
      "C(location)[T.KBH N]            -0.7125      0.217     -3.284      0.001      -1.138      -0.287\n",
      "C(location)[T.KBH O]            -0.2165      0.104     -2.084      0.037      -0.420      -0.013\n",
      "C(location)[T.KBH V]            -0.2927      0.157     -1.867      0.062      -0.600       0.015\n",
      "m2                               0.0084      0.001     10.685      0.000       0.007       0.010\n",
      "C(location)[T.KBH N]:m2         -0.0002      0.001     -0.145      0.884      -0.003       0.003\n",
      "C(location)[T.KBH O]:m2         -0.0002      0.001     -0.162      0.871      -0.002       0.002\n",
      "C(location)[T.KBH V]:m2          0.0002      0.001      0.136      0.892      -0.003       0.003\n",
      "rooms                           -0.0028      0.025     -0.113      0.910      -0.051       0.046\n",
      "C(location)[T.KBH N]:rooms       0.1032      0.038      2.746      0.006       0.029       0.177\n",
      "C(location)[T.KBH O]:rooms      -0.0030      0.034     -0.087      0.930      -0.070       0.064\n",
      "C(location)[T.KBH V]:rooms      -0.0044      0.044     -0.099      0.921      -0.091       0.082\n",
      "toilets                         -0.2184      0.090     -2.419      0.016      -0.396      -0.041\n",
      "C(location)[T.KBH N]:toilets     0.2455      0.215      1.140      0.255      -0.177       0.668\n",
      "C(location)[T.KBH O]:toilets     0.1501      0.104      1.444      0.149      -0.054       0.354\n",
      "C(location)[T.KBH V]:toilets     0.1531      0.160      0.957      0.339      -0.161       0.467\n",
      "================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Estimer modellen. Vi bruger C(location) til automatisk at generere dummies, \n",
    "# hvorefter vi interagerer vores dummies med m2, rooms og toilets.\n",
    "results_3 = smf.ols('logprice ~ C(location)*(m2 + rooms + toilets)', data = df).fit()\n",
    "\n",
    "# Outputtet er meget stort, så her printer vi kun koefficientestimaterne.\n",
    "print(results_3.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1 answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fortolkning af regressionsresultater:\n",
    "> - Kvadratmeterprisen er ca. 0.2 procent lavere på Nørrebro, Østerbro og Vesterbro sammenlignet med Kbh K. Ingen af disse tre estimater er dog individuelt signifikante.\n",
    ">\n",
    "> - Et ekstra værelse på Nørrebro øger prisen med 10 procentpoint mere end et ekstra værelse i Kbh K. Estimatet er signifikant på 5% niveauet. Et ekstra værelse på Østerbro og Vesterbro er ikke signifikant forskelligt fra effekten i Kbh K.\n",
    "> - Et ekstra toilet øger prisen med mellem 15 og 25% mere i Kbh N, Kbh Ø og Kbh V sammenlignet med Kbh K, men disse estimater er heller ikke signifikant forskellige fra nul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2 code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C(location)[T.KBH N]:m2', 'C(location)[T.KBH N]:rooms', 'C(location)[T.KBH N]:toilets', 'C(location)[T.KBH O]:m2', 'C(location)[T.KBH O]:rooms', 'C(location)[T.KBH O]:toilets', 'C(location)[T.KBH V]:m2', 'C(location)[T.KBH V]:rooms', 'C(location)[T.KBH V]:toilets']\n",
      "\n",
      "<F test: F=2.690245861982759, p=0.004299054062713002, df_denom=972, df_num=9>\n",
      "1.889495970496332\n"
     ]
    }
   ],
   "source": [
    "# Generer en liste med interaktionsleddene som vi kan bruge til vores F-test\n",
    "locs = ['KBH N', 'KBH O', 'KBH V']\n",
    "vars = [ 'm2', 'rooms', 'toilets']\n",
    "loc_vars = [f'C(location)[T.{loc}]:{var}' for loc in locs for var in vars]\n",
    "\n",
    "# Print hele listen af variable, vi tester om er lig nul\n",
    "print(loc_vars)\n",
    "print('')\n",
    "\n",
    "# Test om alle interaktionsledene er 0\n",
    "print(results_3.f_test(loc_vars))\n",
    "\n",
    "# Sammenlign med kritisk værdi\n",
    "print(stats.f.ppf(0.95, 9, 972))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2 answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fortolkning af F-test: Vi må forkaste nulhypotesen (at alle interaktionsleddene er lig nul), da F-teststatistikken på 2.69 er højere end den kritiske værdi på 1.89."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3 code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<F test: F=3.536741771963028, p=0.014371546480448005, df_denom=972, df_num=3>\n",
      "2.614060340843658\n"
     ]
    }
   ],
   "source": [
    "# Test at interaktionsledene for rooms er 0\n",
    "hypothesis = [f'C(location)[T.{loc}]:rooms' for loc in locs]\n",
    "print(results_3.f_test(hypothesis))\n",
    "\n",
    "# Sammenlign med kritisk værdi\n",
    "print(stats.f.ppf(0.95, 3, 972))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3 answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fortolkning af F-test: Også her må vi forkaste nulhypotesen (at interaktionsleddene for rooms alle er lig nul), da F-teststatistikken på 3.54 er højere end den kritiske værdi på 2.61."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.4 code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<F test: F=0.029717793380989174, p=0.9931017474102667, df_denom=972, df_num=3>\n",
      "2.614060340843658\n"
     ]
    }
   ],
   "source": [
    "# Test at interaktionsledene for m2 er 0\n",
    "hypothesis = [f'C(location)[T.{loc}]:m2' for loc in locs]\n",
    "print(results_3.f_test(hypothesis))\n",
    "\n",
    "# Sammenlign med kritisk værdi\n",
    "print(stats.f.ppf(0.95, 3, 972))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.4 answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fortolkning af F-test: Her kan vi ikke afvise nulhypotesen (at interaktionsleddene for m2 alle er lig nul), da F-teststatistikken på 0.03 er lavere end den kritiske værdi på 2.61.\n",
    "> Det kan også aflæses af den p-værdi som statsmodels rapporterer på p=0.99\n",
    ">\n",
    "> På baggrund af vores test-resultater kunne det være relevant at estimere en ny model, hvor vi udelader interaktionen mellem m2 og boliglokation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Task 6.\n",
    "**Quadratic model for apartment size.** \n",
    "Model (1) assumes that apartment prices depend linearly on apartment size, but this may be a restrictive assumption. \n",
    "\n",
    "You are therefore asked to estimate a new model including a quadratic term of $m2$. Moreover, the model should allow the effect of the linear and quadratic **m2** terms to be different across locations, while making the simplifying assumption that **rooms** and **toilets** have the same effect on sales prices across locations. \n",
    "\n",
    "- Generate the variable for squared m2 and estimate the new model\n",
    "- Test the new model against a restricted model where all slope parameters are the same across locations in Copenhagen. \n",
    "- Which model do you prefer in this case?\n",
    "- What is the expected effect of increasing $m2$ by one unit on prices?\n",
    "\n",
    "_Hint:_ It might be helpful to scale the squared term by a factor of e.g. 1000 (how will this affect your estimates?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               logprice   R-squared:                       0.623\n",
      "Model:                            OLS   Adj. R-squared:                  0.618\n",
      "Method:                 Least Squares   F-statistic:                     123.7\n",
      "Date:                Wed, 25 Sep 2024   Prob (F-statistic):          1.10e-195\n",
      "Time:                        11:17:48   Log-Likelihood:                -75.341\n",
      "No. Observations:                 988   AIC:                             178.7\n",
      "Df Residuals:                     974   BIC:                             247.2\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                    14.0595      0.057    246.380      0.000      13.948      14.171\n",
      "C(location)[T.KBH N]         -0.8330      0.171     -4.864      0.000      -1.169      -0.497\n",
      "C(location)[T.KBH O]         -0.1242      0.056     -2.211      0.027      -0.234      -0.014\n",
      "C(location)[T.KBH V]         -0.1486      0.072     -2.074      0.038      -0.289      -0.008\n",
      "rooms                         0.0150      0.013      1.117      0.264      -0.011       0.041\n",
      "toilets                      -0.0880      0.041     -2.124      0.034      -0.169      -0.007\n",
      "m2                            0.0069      0.001     11.579      0.000       0.006       0.008\n",
      "C(location)[T.KBH N]:m2       0.0142      0.004      3.315      0.001       0.006       0.023\n",
      "C(location)[T.KBH O]:m2       0.0005      0.001      0.861      0.389      -0.001       0.002\n",
      "C(location)[T.KBH V]:m2       0.0002      0.001      0.244      0.808      -0.001       0.002\n",
      "m2sq                          0.0084      0.002      3.416      0.001       0.004       0.013\n",
      "C(location)[T.KBH N]:m2sq    -0.0712      0.025     -2.826      0.005      -0.121      -0.022\n",
      "C(location)[T.KBH O]:m2sq  4.077e-05      0.003      0.014      0.989      -0.006       0.006\n",
      "C(location)[T.KBH V]:m2sq     0.0002      0.004      0.041      0.967      -0.008       0.008\n",
      "==============================================================================\n",
      "Omnibus:                      149.717   Durbin-Watson:                   2.108\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              379.029\n",
      "Skew:                          -0.809   Prob(JB):                     4.95e-83\n",
      "Kurtosis:                       5.567   Cond. No.                     2.17e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.17e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "df['m2sq'] = df['m2']**2 / 1000\n",
    "results4 = smf.ols('logprice ~  rooms + toilets + C(location)*(m2 + m2sq)', data = df).fit()\n",
    "\n",
    "print(results4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<F test: F=2.4417750765223527, p=0.02386580855912827, df_denom=974, df_num=6>\n",
      "2.1078728884235107\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test at interaktionsledene for m2 og m^2 er 0\n",
    "vars = ['m2', 'm2sq']\n",
    "hypothesis= [f'C(location)[T.{loc}]:{var}' for loc in locs for var in vars]\n",
    "print(results4.f_test(hypothesis))\n",
    "\n",
    "# Sammenlign med kritisk værdi\n",
    "print(stats.f.ppf(0.95, 6, 974))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vi må forkaste nulhypotesen (at hældningsparametrene for m2 er ens på tværs af lokation), da F-teststatistikken på 2.44 er større end den kritiske værdi på 2.11. Det kan også ses på p-værdien på p=0.024, som altså er mindre end 0.05."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
