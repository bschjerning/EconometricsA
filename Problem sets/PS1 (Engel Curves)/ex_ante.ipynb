{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An econometric analysis of Engel curves for Canadian households\n",
    "The aim of problem sets 1 and 2 is to carry out an empirical analysis of Engel curves. As\n",
    "you know from Micro A, Engel curves describe how demand for individual products or a\n",
    "group of products depend on income at given prices. For this analysis, we will use a data\n",
    "set containing information on a large number of Canadian households. The data file is included with this Jupyter Notebook in the PS1 folder on GitHub.\n",
    "\n",
    "The econometric analysis includes several steps. Problem set 1 focuses on selecting, transforming and describing the relevant variables for the analysis. In Problem set 2, we estimate\n",
    "Engel curves using regression analysis and relate the results to economic theory.To help develop your inutiton, see the plot below:\n",
    "![Engel Curves](engel_curves.png)\n",
    "\n",
    "### Data\n",
    "\n",
    "The data are taken from the Canadian Consumer Expenditure Survey. Selected households\n",
    "from 5 regions of Canada have kept a diary of all their expenses for a period of two weeks\n",
    "in 1992. These expenses have been combined in a number of categories. Our data contains\n",
    "the following 11 expenditure categories:\n",
    "\n",
    "| **Expenditure Category** | **Description**                                                    |\n",
    "|----------|--------------------------------------------------------------------|\n",
    "| fath     | Food (food at home)                                                |\n",
    "| rest     | Restaurant                                                         |\n",
    "| hhop     | Phone, cleaning, childcare, electricity, water (household operations) |\n",
    "| wcloth   | Women’s clothing                                                   |\n",
    "| mcloth   | Men’s clothing                                                     |\n",
    "| caruse   | Consumption for car use                                            |\n",
    "| tran     | Transportation                                                     |\n",
    "| care| Medicine, doctor, and dentist                                      |\n",
    "| recr     | Recreation                                                         |\n",
    "| tob      | Tobacco                                                            |\n",
    "| alc      | Alcohol                                                            |\n",
    "\n",
    "\n",
    "In the data set, the variables are named such that _xcategory_ refers to expenditures in that\n",
    "particular _category_. E.g., the _xfath_-variable indicates expenditures on food. In problem set\n",
    "1, we will focus on an analysis of food, alcohol and men’s and women’s clothing.\n",
    "\n",
    "The data set also contains some demographic information. We will use the variable _dmale =\n",
    "1_ if the person is male, _dmale = 0_ if the person is female.\n",
    "\n",
    "To make the analysis as simple as possible, the data set is restricted to include observations of a cross-section collected in 1992. The cross-section contains only singles without\n",
    "children (i.e., household with only one member).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group work\n",
    "Discuss the questions below in groups of max 3 people. Each group should first choose a\n",
    "spokesperson who reports for the group in the subsequent class discussion. The teacher is\n",
    "present and can help clarify issues as you go along.\n",
    "\n",
    "A crucial step in an econometric analysis is to ”translate” economic theory in order to\n",
    "relate it to data and empirical measures. Among other things, this requires you to consider\n",
    "which variables you want to use in the analysis, and whether to transform them or construct\n",
    "new variables.\n",
    "\n",
    "Assume that we want to analyze the correlation between the demand for alcohol and household income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "In this problem set we rely on demand theory. Identify the relevant variables from demand theory.\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Which information in the data can be used as empirical measures of the theoretical\n",
    "variables? Discuss why we can not estimate price effect with the current data set.\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "In the empirical analysis, total consumption is often used instead of income. Consider\n",
    "why. \n",
    "\n",
    "_[Hint: Observe the product categories included in the data set and think about which\n",
    "categories have been omitted.]_\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question 4\n",
    "Why can it be beneficial to analyze data for households with only one member?\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python exercise: Descriptive analysis\n",
    "After having identified the relevant variables, it is time to take a look at the data. A\n",
    "descriptive analysis should be the first step in any empirical analysis. The aim is both to get\n",
    "an overview of the structure of data and also to check whether the data ”looks reasonable”.\n",
    "Often, the data is put together from multiple sources or is drawn from a larger data set. It\n",
    "therefore makes sense to look whether all relevant observations and variables are included\n",
    "(e.g. are there both men and women in our dataset? Is there information on all relevant\n",
    "consumption categories? Are there observations with errors such as negative consumption\n",
    "values?). This initial descriptive analysis is the focus of the first Python exercise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Load the data\n",
    "Data is in the file _engel.dta_ which is included in the PS1 folder on GitHub. \n",
    "\n",
    "To work with the data in Python, we will use the Pandas library, which you can import using this command: \n",
    "```py\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "Then, you can load the dataset as a Pandas DataFrame using the command:\n",
    "```py\n",
    "pd.read_stata('engel.dta')\n",
    "``` \n",
    "Note that the data file must be located in the same folder as this notebook – otherwise, you have to adjust the relative path accordingly.\n",
    "\n",
    "Make sure to assign the DataFrame to a variable so we can access it later. You can name the DataFrame variable anything you like, but often we use `df`.\n",
    "\n",
    "---\n",
    "\n",
    "**Task:** Load the data and assign it to a variable\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_stata('engel.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Examine the data\n",
    "You can get an overview of the data by calling the variable you assigned the DataFrame to. If you named the variable `df`, you simply run the command `df` to get an overview.\n",
    "\n",
    "A few basic Pandas tips:\n",
    "\n",
    "- To see the names of the variables in the dataframe, you can run `df.columns`\n",
    "\n",
    "- To get the dimensions of a DataFrame, you can use `df.shape`\n",
    "\n",
    "- To access a specific column (for example, the _xalc_ column), you can either use `df['xalc']` or `df.xalc`\n",
    "\n",
    "If you want to create a view of the DataFrame where you only see a list of specific variables, you can index the DataFrame using a list of labels. For example, to create a view that only shows the alcohol, tobacco and recreation expenditures, you can use the code:\n",
    "\n",
    "```py\n",
    "vars = ['xalc', 'xtob', 'xrecr']\n",
    "df[vars]\n",
    "```\n",
    "or alternatively the one-liner:\n",
    "```py\n",
    "df[['xalc', 'xtob', 'xrecr']]\n",
    "```\n",
    "\n",
    "You can also index the DataFrame based on conditional logic. This is basically the same thing as using a filter in Excel. For example, if I want to only see the households where tobacco consumption is greater than 50, I would use the code:\n",
    "```py\n",
    "I = df.xtob > 500\n",
    "df[I]\n",
    "```\n",
    "\n",
    "The first line above creates a boolean vector `I` that is True or False for each household depending on whether their tobacco consumption is greater than 500 or not. In the second line, I use this vector to 'filter' the DataFrame so only the households satisfying the condition show up in the resulting view.\n",
    "\n",
    "This can also be done in a one-liner:\n",
    "```py\n",
    "df[df.xtob > 500]\n",
    "```\n",
    "It is possible to combine multiple 'filters':\n",
    "```py\n",
    "df[(df.xtob > 500) & (df.xalc < 1000)]\n",
    "```\n",
    "---\n",
    "**Task:** Now, using the tools described above, answer these questions:\n",
    "- How many households are there in the data set? \n",
    "\n",
    "- What information is provided for each household? \n",
    "- How many households spent more than 3000 on food expenditures during the survey?\n",
    "- Are there households with negative food expenditures, and is it realistic? The purpose of this question is to verify that the data does not contain error observations.\n",
    "\n",
    "\n",
    "\n",
    "**Your answer:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 43)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Compute total expenditure\n",
    "\n",
    "We can add new variables (columns) to a DataFrame in a similar way to how we assign values to other variables in Python.\n",
    "\n",
    "For instance, if we wanted to add a variable to the DataFrame containing the total clothing expenditures for each household, we could use this code: \n",
    "```py\n",
    "df['xcloth_total'] = df['xwcloth'] + df['xmcloth']\n",
    "``` \n",
    "\n",
    "This creates a new variable in the DataFrame called _xcloth_total_ that contains the sum of the expenditures on men's clothing and women's clothing for each household.\n",
    "\n",
    "If we want to calculate a sum across many variables, we can first create a view of our DataFrame containing just those variables, and then use the `.sum()` method. For example, we could compute the sum of alcohol, tobacco and recreation expenses using the code:\n",
    "```py\n",
    "vars = ['xtob', 'xalc', 'xrecr']\n",
    "df[vars].sum(axis=1)\n",
    "```\n",
    "The argument `axis=1` tells Pandas to compute the horizontal sum instead of the vertical sum in the DataFrame. Specifying `axis=0` would take the sum across all observations instead of across the chosen variables. Be aware that if you just use `.sum()` without specifying the axis, it will default to 0.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "**Task:** Now, construct a variable in the DataFrame for total expenditures across all 11 expenditure categories.\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Construct expenditure shares for food, clothes and alcohol\n",
    "**Task:** Create three new variables in the DataFrame where you compute the expenditure share for the food, clothes and alcohol categories. In other words: Calculate how big a percentage of the total expenditures each of these categories constitute.\n",
    "\n",
    "Why is it easier (and more meaningful) to work with expenditure share of a category\n",
    "rather than spending in absolute terms?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Explore the data using scatter plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make visualizations based on Pandas DataFrames, we can use the library Seaborn. You can import Seaborn using the code:\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "```\n",
    "\n",
    "To create a scatterplot using seaborn, we use the `sns.scatterplot()` method. This method allows us to specify a variable for the x-axis, for the y-axis and the DataFrame to grab the data from. For example, to explore the relationship between alcohol and tobaco consumption,  we can specify: \n",
    "\n",
    "```python\n",
    "sns.scatterplot(x='xalc', y='xtob', data=df)\n",
    "```\n",
    "\n",
    "To learn more about how to use this method, you can run the code `?sns.scatterplot`. This is a great way of exploring various methods included in other libraries (such as Pandas) too.\n",
    "\n",
    "If we want to create multiple scatterplots where we subdivide the data based on a category (for example, by gender), we can use the method `sns.relplot()` instead of `sns.scatterplot()`. The syntax for `sns.relplot()` is very similar, but it allows us to add an extra `col` argument to specify which variable we should use to categorize the data. For example, to explore the relationship between alcohol and tobaco consumption by gender, we can use this command: \n",
    "\n",
    "```python\n",
    "sns.relplot(x='xalc', y='xtob', col='dmale', data=df)\n",
    "```\n",
    "Remember: the variable _dmale_ indicates if a person is male (1) or woman (0).\n",
    "\n",
    "You can learn more about Seaborn in general here: https://seaborn.pydata.org/tutorial/introduction.html\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Now, plot the expenditure share on food against total\n",
    "expenditures for men and women, respectively. Do the same for expenditure shares on\n",
    "clothes and alcohol.\n",
    "Do you generally see a positive, negative or no correlation between the expenditure\n",
    "share on food (clothing, alcohol) and total expenditures?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Exercise 6: Do a brief descriptive analysis\n",
    "We can easily compute summary statistics (such as the mean, standard deviation and different quantiles) for variables in a Pandas DataFrame by using the `df.describe()` method.\n",
    "\n",
    "If we want to group the data by some category, e.g. gender, we can use the method `df.groupby('dmale')` before we use the `.describe()` method. \n",
    "\n",
    "Alternatively, we can manually limit the dataframe to a specific category before we use the describe method. Then we need to do two tables:\n",
    "```py\n",
    "df[df.dmale == 1].describe()\n",
    "df[df.dmale == 0].describe()\n",
    "```\n",
    "\n",
    "Before using the `.describe()` method, we usually need to create a view where we narrow down our DataFrame so it only shows the variables of interest. Otherwise, the resulting table becomes way to big – especially when we also group by categories. If for example we want to compute descriptive statistics for only the alcohol, tobacco and recreation expenditure variables, you can use the code:\n",
    "```py\n",
    "vars = ['xalc', 'xtob', 'xrecr']\n",
    "df[vars].describe()\n",
    "```\n",
    "or you  can do a one-liner:\n",
    "```py\n",
    "df[['xalc', 'xtob', 'xrecr']].describe()\n",
    "```\n",
    "\n",
    "**Tip:** If you still end up having too many variables to comfortably fit on the screen, it can sometimes help to transpose the table – such that the variables are the rows and the statistics are the columns. To do this, simply add `.T` at the end of your command: `df.describe().T`.\n",
    "\n",
    "**Tip:** If you want to round the output of a Pandas DataFrame to 3 decimal points, you can add `.round(3)` at the end of your command: `df.describe().round(3)`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Now, carry out a brief descriptive analysis of the three expenditure share variables we constructed in exercise 3 as well as total consumption **for each gender**. Comment briefly on the table while you highlight main features of the\n",
    "data, and possibly error observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
